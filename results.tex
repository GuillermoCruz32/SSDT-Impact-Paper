\section{RESULTS}
% MOVE This internship model has produced such favorable outcomes that it has been implemented consecutively for five years. Early on, the team took on every project that was pitched to the team, resulting in five applications in the first five years. However, by the third year, the team had to bear in mind the maintenance of existing systems in addition to creating new software. Adoption slowed, but did not stop...

In evaluating the effectiveness of the software generated by the SSDT, a survey was issued to all product owners asking them to evaluate the software. The metrics were primarily informed by DeLone and McLean's Model for Information Software Success \cite{delone1992softwaresuccess}. Their model consists of six measures of success: system quality, information quality, use, user satisfaction, individual impact, and organizational impact. The questions developed aligned with three of the six components from this model. System quality and information quality were excluded, since product owners are not always able to accurately judge these metrics; use was excluded due to the controversial nature of its applicability to measuring software success \cite{delone2003delone}. 

% TODO what metrics from AM and how were our PO's able to judge them?
% CUT FROM ABOVE Additionally, the SSDT leveraged the Agile Manifesto \cite{agilemanifesto} as a guiding set of principles for developing software. A survey was developed and issued to the product owners of each of the eight applications built by the SSDT. 
\subsection{Participants}
Participants in this study included fifteen institutional employees who are all product owners of a software system developed by the SSDT. Ten out of the fifteen product owners responded to the survey. The ten respondents represented product owners from six of the eight applications built by the SSDT. None of the product owners are software experts.

\subsection{Evaluation of Software Success}
 To measure user satisfaction, the product owners were asked to evaluate the software on four metrics: is the software easy to use and learn; did they feel confident when using the software; was this software useful to their job; and was their level of software competency relevant to their ability to use the new software. Individual impact was evaluated on four questions: does the software meet their needs; did the application make their job better; did the application allow them to do their job faster; and did completing a task after the software take less time than before. Last, organizational impact was measured using the following six questions: are their day-to-day tasks and work dependent on the software; did the application improve the institution as a whole; if the software was completely removed, would it cost them a lot in terms of time;  stress;  money; and errors. Responses to all fourteen questions were overwhelmingly positive. Table \ref{tab:surveyResults} summarizes the ten product owner's responses to the survey. 

\begin{table}
\caption{Survey Results. Scale: Strongly agree (SA), Agree (A), Neutral (N), Disagree (D), and Strongly Disagree (SD)}
\label{tab:surveyResults}
\begin{tabular}{p{3.0cm}p{.6cm}p{.6cm}p{.6cm}p{.6cm}p{.6cm}}
Question: & SA & A & N & D & SD \\
 \hline
User satisfaction \newline(4 questions) & 62.5\% & 22.5\% & 12.5\% & 2.5\% & 0.0\% \\
Individual Impact \newline(4 questions) & 67.5\% & 17.5\% & 7.5\% & 5.0\% & 2.5\% \\
Organizational Impact \newline(6 questions) & 56.7\% & 26.7\% & 10.0\% & 1.7\% & 5.0\% \\
\end{tabular}
\end{table}

Regarding user satisfaction, all ten respondents indicated they were very satisfied or satisfied with their software. This was encouraging news given the program has been operational for five years. One respondent indicated that their level of software competency was relevant to their ability to use the software, meaning that their lack of experience using software impacted their ability to use the software built for them. 

Responses to the four questions about individual impact revealed most users (85\%) were able to do their job better and faster, and the application met their individual needs. Some participants noted significant changes in the amount time spent completing certain task; one product owner indicated a work reduction of about 180 hours per semester after the software was implemented.

%%Only two users indicated that certain tasks were slower because of the software; of those two, only one indicated they are slower at their job overall because of the software. While discouraging, the survey did not capture if the software prevented errors or allowed users to enter more information, which may explain why tasks took longer. Future work will take this into consideration.

Lastly, the six questions about organizational impact revealed that product owners felt the software was valuable to the institution, with 83.4\% of all responses in the positive. Of the negative responses, three product owners indicated that removing the software would not cost them a lot in terms of money, and one respondent did not feel the application improved the institution as a whole. 

Despite undergraduates developing the software, some with little to no design or web development experience coming into the experience, the students are still capable of producing quality software that is satisfactory to the needs of the product owners. Overall, the software meets the needs of product owners in improving their ability to do their daily work, is easy to use and learn, makes their jobs easier and faster, and provides value to the institution. 

% \begin{table}
% \caption{User Satisfaction - Survey Results. The scale is: Strongly agree (SA), Agree (A), Neutral (N), Disagree (D), and Strongly Disagree (SD)}
% \label{table:usersatisfaction}
% \begin{tabular}{p{4.3cm}p{.4cm}p{.4cm}p{.38cm}p{.4cm}p{.4cm}}
% Question: & SA & A & N & D & SD \\
%  \hline
% Software easy to use/learn & 80\% & 20\% & 0\% & 0\% & 0\% \\
% Makes job better & 70\% & 20\% & 10\% & 0\% & 0\% \\
% I feel confident using software & 60\% & 40\% & 0\% & 0\% & 0\% \\
% Software useful to my job & 90\% & 10\% & 0\% & 0\% & 0\% \\
% My level of software competency irrelevant & 20\% & 20\% & 50\% & 10\% & 0\% \\
% \end{tabular}
% \end{table}


% Rewrite like the others...
% CUT 4p Respondents were overwhelmingly positive about user satisfaction; All ten product owners indicated the features were easy to use, was useful to their job, and they were all confident in their ability to use the software. 90\% also indicated the software made their job better. When asked if the product owner's prior knowledge played into their ability to use the software, the responses were split; 50\% of respondents were neither in agreement or disagreement with the statement, while 40\% indicated their prior experience did not play a role in their ability to use their software. One respondent indicated that their prior software competency was important to their ability to use the software.

% MOVED UP Despite undergraduates designing and building the software, some with little to no design or web development experience coming into the experience, the students are still capable of producing software that is satisfactory to the needs of the customers; in our case, faculty, staff, and administrators at the academic institution. % End this paragraph with the best quote related to user satisfaction...

% CUT The users were asked to rate how useful the primary features of the software were to them and to their daily tasks. This is an important measure because when designing software for a customer, it is important that {insert more words here}. The results of this component of the survey showed that nine out of ten respondents answered that the primary feature within the software that they use is ``Essential''; the tenth respondent marked that the primary feature was ``Useful". Moreover, pertaining to all 16 features in the applications, 15 out of the 16 total features were marked as ``Essential'' and one being marked as ``Useful''. This response shows that all of the applications that were built by the student development team were applicable to the responsibilities attributed to them on a daily basis. [Talk about why having useful software makes it successful].

% CUT 4p Within the four questions, the users were asked to rate how useful the primary features of the software were to them and to their daily tasks. Respondents were overwhelmingly positive about user satisfaction; 80\% of users indicated that they ``strongly agreed'' that the features in the application were easy to use and two answered that they ``agreed'' that features were easy to use. Easy of use and learnability are important components of the user satisfaction measure when designing software for a customer because it is critical to the SSDT that it does not provide a ``solution'' that only makes the users' worklife more difficult. The results of this component of the survey also showed that nine out of ten respondents answered that they ``strongly agree'' that the primary feature within the respective softwares is useful; the tenth respondent marked that they ``agree'' that  primary feature was useful. One participant of the survey added in the optional commentary that their favorite aspects of the syllabi archival software was that it allowed them to  ``find the syllabi that I need'' and ``I can go back to previous terms pretty easily''. This participant in particular is an administrator of the syllabi software who provides support to the professors at the institution who use the non-administrative version of the application; they went on to say ``I can easily tell who hasn't submitted their syllabi". This user's testimony further substantiates the results of the initial question about the software's ease of use, overall learnability, and usefulness.

% CUT 4p The final two questions of the user satisfaction portion of the survey asked the product owners to expresse the extent of their agreement with the following two statements as it pertains to the particular application that they utilize: ``The application makes my job better'' and ``I feel confident while using the application.'' Out of the ten respondents, eight product owners said that they ``Strongly Agree'' that the application makes their job better. One of the two other users answered that they ``Agree'' with the statement and the last remained ``Neutral'' on the question.  Dalcher \cite{dalcher2009software} suggests that quality solutions emerge from the consideration of effectiveness and that to attain project success one needs to relate the quality aspects and perspectives related to the effectiveness of the project. The software built by the SSDT prioritzes the effectiveness of the solution in order to provide a more favorable product to the users. In response to the statement about their confidence in using the application, seventy percent of the participants answered that they ``Strong Agree" with the statement whilst the other three all answered that they ``Agree'' with the statement. The user's confidence in their usage of the application attributes to the user's satisfaction by allowing the user to complete their everyday tasks without worry of errors or confusion.


 %Moreover, pertaining to all 16 features in the applications, 15 out of the 16 total features were marked as Essential and one being marked as Useful. This response shows that all of the applications that were built by the student development team were applicable to the responsibilities attributed to them on a daily basis. Talk about why having useful software makes it successful%

% CUT Last in regards to the user satisfaction measurement of software success, the product owners expresses the extent of their agreeance with the following two statements as it pertains to the particular application that they utilize: ``The application makes my job better'' and ``I feel confident while using the application.'' Out of the ten respondents, eight product owners said that they ``Strongly Agree'' that the application makes their job better. [Include why having an application improve quality of work is good] One of the two other users answered that they ``Agree'' with the statement and the last remained ``Neutral'' on the question. In response to their confidence about using the application, seven out of ten of the users answered that they ``Strong Agree" with the statement whilst the other three all answered that they ``Agree'' with the statement. [Talk about why confide is good here]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CUT THIS WHOLE SECTION BECAUSE OUR SURVEY DATA DOESN'T ALIGN WITH IT.

% \subsubsection{Use}
%  % This section (our description of the use metric) and the survey questions do not align AT ALL!
% According to DeLone and McLean, the use metric weighs the frequency of use, the length of time using the software, and the number of users who actually utilize the software \cite{delone1992softwaresuccess}. For this component, the product owners were asked to rate two statements about their usage of their software system: ``The application makes my job faster'' and ``My level of competency with software is not relevant when using the application.'' Table \ref{tab:use} summarizes the results from the same ten respondents. 

% % The survey also posed questions about how often each user engaged with the application (daily, weekly, monthly, yearly, once per semester, or never)  and how long the user interacts with the application (less than 15 minutes, between 15 and 30 minutes, between 30 minutes and an hour, between one to two hours, and over two hours per session).

% CUT 4p
% \begin{table}
% \caption{Use - Survey Results. The scale is: Strongly agree (SA), Agree (A), Neutral (N), Disagree (D), and Strongly Disagree (SD)}
% \label{table:use}
% \begin{tabular}{p{4.3cm}p{.4cm}p{.4cm}p{.4cm}p{.4cm}p{.4cm}}
% Question: & SA & A & N & D & SD \\ 
% \hline
% Allows me to do my job faster & 80\% & 10\% & 0\% & 0\% & 10\% \\
% My level of software competency irrelevant & 20\% & 20\% & 50\% & 10\% & 0\% \\
% \end{tabular}
% \end{table}

% The survey revealed that 90\% of responses felt the software allowed them to do their job faster. In the one case where it was indicated that the software did not make their job faster, the respondent indicated that they are, however, able to do their job more accurately and completely, despite it not being faster. When asked if the product owner's prior knowledge played into their ability to use the software, the responses were split; 50\% of respondents were neither in agreement or disagreement with the statement, while 40\% indicated their prior experience did not play a role in their ability to use their software. One respondent indicated that their prior software competency was important to their ability to use the software.  

% Post-data summary of what we think. Unfortunately, it's hard to answer because the questions don't align with USE


% CUT The use of an application is important because '[describe why this is important]'. When asked if the application allows the user to do their job faster, eight of the user responded that they ``Strongly Agree'' with the statement, one user responded that they ``Agree'' with the statement, and one user remained ``Neutral'' on the statement.

% CUT 4p Last, the users were asked how long they typically engage with the software whe they use it to do their work. Fifty percent of the users answered that they use the software between 15 to 30 minutes whilst 40\% of the users answered that they engaged with the software from 30 minutes to an hour at a time. Only one user answered that they used the software for fifteen minutes or less.


% CUT The users were asked if their level of software competency was relevant when using the application. In other words, does the user think that they have to have some level technical knowledge in order to use the application. The responses to this question were more varied than previous questions. Two respondents answered that they ``Strongly Agree'' with the statement,  two responded that they ``Agree'' with the statement, five respondents remained ``Neutral'' on the question, and one respondent answered that they ``Disagree'' with the statement.

% THIS paragraph is actually about use. Though, it doesn't tell much of a story, since the appropriate usage might be that it's only used daily/weekly/monthly/yearly. We may need to scrap the USE section...
% The users were also asked how often that they interacted with the software while using it. The answers to the question regarding the amount of time that the respondents used the software vary because though all of the users are product owners of one of the application, they have different roles at the institution and utilize the software differently. This question was followed by a an optional short answer box in case the respondent wanted to elaborate on their answer about usage. It was found that 50\% of the users engaged with the application monthly, one user engaged the software on a weekly and three users engage the software on a daily basis. One user responded that they engaged with the software once per year, however, this result was expected because this software is used for faculty at the institution who participate in summer research, thus the application only needing to be used during once per year during the application process.

% % Again, this may be the appropriate amount of time for each use case. It doesn't really tell us what USE is defined as.
% Last, the users were asked how long they typically engage with the software when they use it to do their work. Fifty percent of the users answered that they use the software between 15 to 30 minutes whilst 40\% of the users answered that they engaged with the software from 30 minutes to an hour at a time. Only one user answered that they used the software for fifteen minutes or less.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CUT 4p \subsubsection{Individual Impact}
% Individual impact is loosely based on the user's personal interactions with the software and its effects on them. Individual impact includes the user's confidence when using the software, improved personal productivity, the amount of time it takes to complete a task as compared to when the user did not have the software, as well the amount of effort that is put into using the software. Product owners were asked to estimate how much time they spent completing tasks before the software was implemented, and how much time it took to complete the same task using the software. The product owner was also asked if the software met their needs as defined in their initial request. Also, product owners were asked if the application helped make their job go faster. Finally, they were asked how much of their day-to-day responsibilities and work depended on their ability to use the newly developed application. Table \ref{table:individualImpact} summarizes the product owner's responses to each question.

% CUT 4p
% \begin{table}
% \caption{Individual Impact - Survey Results. The scale is: Strongly agree (SA), Agree (A), Neutral (N), Disagree (D), and Strongly Disagree (SD)}
% \label{table:individualImpact}
% \begin{tabular}{p{4.3cm}p{.4cm}p{.4cm}p{.4cm}p{.4cm}p{.4cm}}
% Question: & SA & A & N & D & SD \\
% \hline
% Before software, tasks took long time & 50\% & 20\% & 10\% & 20\% & 0\% \\
% After software, tasks became quicker & 70\% & 0\% & 10\% & 20\% & 0\% \\
% Application meets my needs & 50\% & 40\% & 10\% & 0\% & 0\% \\
% Allows me to do my job faster & 80\% & 10\% & 0\% & 0\% & 10\% \\
% \end{tabular}
% \end{table}

% CUT 4p Respondents overwhelming agreed that the software met their individual needs, with 90\% positive responses. The survey revealed that 90\% of responses felt the software allowed them to do their job faster. When comparing the questions related to length of time spent doing tasks before and after the software was implemented, 70\% of respondents agreed that they were both now quicker than before, and tasks took too long prior to the software. % Closing thought...

% Conclusion? Future work will include other metrics for measuring individual impact, such as accuracy, error prevention and mitigation, and task efficiency. 

% CUT 4p \subsubsection{Organizational Impact}
% CUT 4pLastly, organizational impact evaluates the organizational goals of the institution, cost reduction, and the efficiency and effectiveness of software to the organization. The product owners gauged organizational impact on six questions. Four of the questions asked the product owner about the cost in terms of money, stress, errors, and time if the new software was suddenly completely taken down and they had to revert back to their previous processes; the fifth questions asked product owners to evaluate the significance of the software to their daily duties, an indicator of the importance of the software to that department's operation. Lastly, product owners were asked to directly evaluate if the software improved the organization as a whole. Table \ref{table:orgImpact} summarizes the product owner's responses.

%The fifth questions asked product owners to estimate the value of the software in comparison to other applications used at the institution that were not built by the SSDT. 

% CUT 4p
% \begin{table}
% \caption{Organizational Impact - Survey Results. The scale is: Strongly agree (SA), Agree (A), Neutral (N), Disagree (D), and Strongly Disagree (SD)}
% \label{table:orgImpact}
% \begin{tabular}{p{4.3cm}p{.4cm}p{.4cm}p{.4cm}p{.4cm}p{.4cm}}
% Question: & SA & A & N & D & SD \\
% \hline
% Daily work depends on software & 60\% & 40\% & 0\% & 0\% & 0\% \\
% Software improved the inst. as whole. & 70\% & 20\% & 0\% & 10\% & 0\% \\
% Removing software would cost time. & 80\% & 10\% & 10\% & 0\% & 0\% \\
% Removing software would create stress. & 40\% & 40\% & 20\% & 0\% & 0\% \\
% Removing software would cost money. & 50\% & 10\% & 10\% & 0\% & 30\% \\
% Removing software would create errors. & 40\% & 40\% & 20\% & 0\% & 0\% \\
% \end{tabular}
% \end{table}


% CUT 4p When considering the cost of the software in terms of time, money, stress, and errors were the system to be removed, responses aligned with our expectations; over 80\% of respondents agreed with a high cost. Regarding monetary costs, 60\% of respondents agreed there would be a high cost penalty were the software eliminated. This slightly lower metric is likely due to the fact that none of the software created by SSDT earns any money; they all improve processes within departments, which saves money through reduced labor costs doing tasks that can be automated through software. All respondents indicated their daily work depended on the software, indicating there is a lot of value derived by our product owners from having this software. Lastly, 90\% indicated that the software improves the institution as a whole. Clearly, our product owners believe in the value of the software generated by the SSDT.